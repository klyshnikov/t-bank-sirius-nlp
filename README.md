# Решение задачи NLP. Классификация отзывов

Файл с предсказаниями - result.csv

Ноутбук с решенеим - t_bank_sirius_nlp_clear.ipynb

## Описание решения

Для начала нам надо разметить данные. План такой: если в тексте явно встречаются слова (из keywords_raw),
то относим к категории. Причем делаем это, если встретили ТОЛЬКО 1 совпадение (иначе могут быть неточности).
В остальных случаях делаем ансамбль из 3 моделей. Самой сильной даем вес 0,6, а остальным по 0,2. Результаты предсказаний умножаем на веса
и складываем. Таким образом, мы не даем одной модели ошибаться, а компенсирем другими. 

Далее, если уверенность предсказания меньше 0,6 - откидываем объект. То есть модель обучается только на тех примерах, на которых предсказания категорий были сделаны "уверенно".

Далее сделаем аугментацию до максимум 12 примеров на каждый класс. Дело в том, что объектов некоторого класса очень мало, и при делении на train/val
в трейне будет мало данных для обучеиня, а в валидации может оказаться класс, который будет очень плохо предсказываться, поэтому метрика на будет хорошо оценивать модель.
Поэтому надо добавить данные на основе тех, что есть. Для этого используем backtranslate (перевод на англ и наоборот) и paraphrase с сохранением смысла. 

Далее делим на train/val так, чтобы классы распределялись равным образом с соотношением около 2 к 8. 

За основу обучения берем модель xlm-roberta-base. Добавляем LoRA, оборачиваем в PERT и обучаем. На валидации получаем f1=0.82. Можно добить до 0.9, но там уже как будто модель
переобучается. 

В конце делаем предсказания для test и формируем конечный csv.

Вообще главная проблема в том, что модель сильно подстраивается под обучающие данные. Например, если в категории "товары для детей" часто упоминается про то, у товара маленький размер,
то итоговая модель на тесте будет относить в "товары для детей" те, которые покупателю не подошли по размеру, особенно если они маленькие, а не только детские. Примерно такая же ситуация с 
остальными категориями. Получается, что модель больше относит к какой-то характиристике на классах, у которых мало обучающих данных (модель сильно загоняется под них). 

P.S. на всякий закинул .py решение, ибо ноутбук не хочет открываться в гитхабе
